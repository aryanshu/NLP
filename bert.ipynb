{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryanshu/NLP/blob/master/bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WQMiGD_6Rgh",
        "colab_type": "code",
        "outputId": "4ee484b8-7f24-4103-a8a6-4fba3170aa32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56SkrTIiBB-P",
        "colab_type": "code",
        "outputId": "823c4a09-d421-4dc9-d9b9-6f19b11cfcb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd \"/gdrive/My Drive/Colab Notebooks/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgH70DJ5lxwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qleDnfWCCOGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGFmgBIOCJ4h",
        "colab_type": "code",
        "outputId": "0fec0334-7ef4-4eb7-9982-d1ad84672e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.11.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.32)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.32)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOuuf-uACTmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CmtP6tJgHdJ",
        "colab_type": "code",
        "outputId": "386612f7-bc27-45f0-f994-4046e29bd14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "train_file_name = './datasets-v5/task-1/task1.train.txt'\n",
        "train_file_name\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntrain_file_name = './datasets-v5/task-1/task1.train.txt'\\ntrain_file_name\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbg9R6TOgW07",
        "colab_type": "code",
        "outputId": "9be25fd0-422c-4ad5-de05-b137633e2ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "articles_id, articles_content, gold_labels = ([], [], [])\n",
        "with open(train_file_name, \"r\", encoding='utf-8') as f:\n",
        "    for line in f.readlines():\n",
        "        article_content, article_id, gold_label = line.rstrip().split(\"\\t\")\n",
        "        articles_id.append(article_id)\n",
        "        articles_content.append(article_content)\n",
        "        gold_labels.append(gold_label)\n",
        "print(\"Number of documents in the training set: %d\"%(len(articles_content)))\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\narticles_id, articles_content, gold_labels = ([], [], [])\\nwith open(train_file_name, \"r\", encoding=\\'utf-8\\') as f:\\n    for line in f.readlines():\\n        article_content, article_id, gold_label = line.rstrip().split(\"\\t\")\\n        articles_id.append(article_id)\\n        articles_content.append(article_content)\\n        gold_labels.append(gold_label)\\nprint(\"Number of documents in the training set: %d\"%(len(articles_content)))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3YV7f-ggayd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train = pd.DataFrame({'id':articles_id, 'text': articles_content, 'target': gold_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vamAXjXqCXqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7ZP5i_Eg993",
        "colab_type": "code",
        "outputId": "6188cbd0-503e-4a6e-df07-a6d7bf5412e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "train[\"target\"][train[\"target\"]==\"non-propaganda\"]=0\n",
        "train[\"target\"][train[\"target\"]==\"propaganda\"]=1\n",
        "train.head()\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain[\"target\"][train[\"target\"]==\"non-propaganda\"]=0\\ntrain[\"target\"][train[\"target\"]==\"propaganda\"]=1\\ntrain.head()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbPmIp6ggvNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train.target=train.target.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlaJLzSEDed0",
        "colab_type": "code",
        "outputId": "3d5c9ef4-399e-471d-b7f5-6f3cbe51c625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "train_df_bert = pd.DataFrame({\n",
        "    'id':range(len(train)),\n",
        "    'label':train.iloc[:,2],\n",
        "    'alpha':['a']*train.shape[0],\n",
        "    'text': train.iloc[:,1].replace(r'\\n', ' ', regex=True)\n",
        "})\n",
        "\n",
        "train_df_bert.head()\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntrain_df_bert = pd.DataFrame({\\n    'id':range(len(train)),\\n    'label':train.iloc[:,2],\\n    'alpha':['a']*train.shape[0],\\n    'text': train.iloc[:,1].replace(r'\\n', ' ', regex=True)\\n})\\n\\ntrain_df_bert.head()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W62DcytwF0bt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_df_bert.to_csv('train.tsv', sep='\\t', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBPkj4_9GKSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXUX-jGcGdXD",
        "colab_type": "code",
        "outputId": "6ed30f46-172e-4413-cc9e-63e6d55fc1eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>Et tu, Rhody?  A recent editorial in the Provi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>A recent post in The Farmington Mirror — our t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>President Donald Trump, as he often does while...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>February is Black History Month, and nothing l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>The snow was so heavy, whipped up by gusting w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_source  ...                                           sentence\n",
              "0                0  ...  Et tu, Rhody?  A recent editorial in the Provi...\n",
              "1                1  ...  A recent post in The Farmington Mirror — our t...\n",
              "2                2  ...  President Donald Trump, as he often does while...\n",
              "3                3  ...  February is Black History Month, and nothing l...\n",
              "4                4  ...  The snow was so heavy, whipped up by gusting w...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PotgG8voCfqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.sentence.values\n",
        "\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTkplwUuCz5X",
        "colab_type": "code",
        "outputId": "df5bd0e7-5a99-4204-907f-1ecd30047417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenize the first sentence:\n",
            "['[CLS]', 'et', 'tu', ',', 'r', '##ho', '##dy', '?', 'a', 'recent', 'editorial', 'in', 'the', 'providence', 'journal', 'catalog', '##ed', 'everything', 'it', 'could', 'find', 'wrong', 'with', 'connecticut', 'and', 'ended', 'with', 'this', 'suggestion', ':', '“', 'gov', '.', 'gina', 'rai', '##mond', '##o', 'should', 'see', 'if', 'at', 'least', 'some', 'of', 'those', 'jobs', 'could', 'come', 'to', 'rhode', 'island', '.', 'it', 'is', 'certainly', 'less', 'risky', 'than', 'the', 'nut', '##me', '##g', 'state', '.', '”', 'we', 'beg', 'your', 'pardon', '.', 'the', 'state', 'with', 'world', '-', 'famous', 'pension', 'problems', 'and', 'persistent', 'economic', 'issues', 'of', 'its', 'own', 'is', '“', 'less', 'risky', '”', '?', 'the', 'journal', 'itself', 'reported', 'just', 'a', 'few', 'weeks', 'ago', 'on', 'rhode', 'island', '’', 's', 'own', 'significant', 'economic', 'problems', ',', 'which', 'in', 'many', 'ways', 'reflect', 'connecticut', '’', 's', '.', 'rhode', 'island', 'enjoys', 'a', 'legacy', 'of', 'corruption', 'that', 'not', 'even', 'connecticut', 'can', 'match', '.', 'the', 'pro', '##jo', 'won', 'a', 'pulitzer', 'prize', 'in', '1994', 'for', 'uncover', '##ing', 'widespread', 'corruption', 'within', 'its', 'own', 'court', 'system', '.', 'what', ',', 'exactly', ',', 'is', 'to', 'be', 'gained', 'from', 'moving', 'to', 'rhode', 'island', '?', 'like', 'connecticut', ',', 'rhode', 'island', 'has', 'an', 'income', 'tax', 'and', 'an', 'estate', 'tax', 'with', 'comparable', 'rates', '.', '(', 'forbes', 'magazine', 'listed', 'it', 'as', 'one', 'of', 'the', 'states', '“', 'where', 'not', 'to', 'die', '.', '”', 'connecticut', 'made', 'the', 'list', ',', 'too', '.', ')', 'connecticut', 'and', 'rhode', 'island', '’', 's', 'inter', '##de', '##pen', '##den', '##ce', 'has', 'been', 'limited', ',', 'with', 'the', 'exception', 'of', 'the', 'interstate', 'economy', 'created', 'by', 'electric', 'boat', 'in', 'gr', '##oton', '.', 'there', 'have', 'been', 'no', 'border', 'wars', 'and', 'very', 'little', 'blood', '##shed', '.', 'a', 'few', 'jokes', 'about', 'rhode', 'island', '’', 's', 'size', ',', 'maybe', ',', 'but', 'if', 'we', '’', 're', 'being', 'honest', ',', 'connecticut', 'doesn', '’', 't', 'really', 'have', 'a', 'lot', 'going', 'on', 'in', 'that', 'department', 'either', '.', 'a', 'little', 'interstate', 'competition', 'is', 'fine', ',', 'but', 'if', 'connecticut', 'suffers', ',', 'so', 'does', 'rhode', 'island', '—', 'and', 'all', 'of', 'new', 'england', ',', 'for', 'that', 'matter', '.', 'connecticut', 'is', 'losing', 'residents', 'at', 'a', 'tr', '##ou', '##bling', 'rate', ',', 'but', 'rhode', 'island', 'has', 'an', 'out', '##mi', '##gration', 'problem', 'of', 'its', 'own', '.', 'from', '2015', 'to', '2016', ',', 'the', 'ocean', 'state', 'experienced', 'a', 'net', 'loss', 'of', 'about', '2', ',', '000', 'tax', 'file', '##rs', ',', 'who', 'took', 'with', 'them', 'more', 'than', '$', '182', 'million', 'in', 'adjusted', 'gross', 'income', '.', 'the', 'top', 'destination', 'states', 'for', 'people', 'who', 'fled', 'rhode', 'island', 'were', 'massachusetts', ',', 'florida', 'and', '—', 'wait', 'for', 'it', '—', 'connecticut', '.', 'connecticut', 'residents', 'moved', 'to', 'rhode', 'island', 'as', 'well', ',', 'of', 'course', '.', 'but', 'connecticut', '’', 's', 'population', 'is', '3', '##½', 'times', 'as', 'big', 'as', 'rhode', 'island', '’', 's', '.', 'so', 'the', '1', ',', '175', 'tax', 'file', '##rs', 'who', 'left', 'rhode', 'island', 'for', 'connecticut', 'represent', 'a', 'far', 'larger', 'portion', 'of', 'the', 'ocean', 'state', 'than', 'the', '1', ',', '220', 'who', 'moved', 'from', 'connecticut', 'to', 'rhode', 'island', '.', 'if', 'any', 'state', 'should', 'be', 'concerned', 'about', 'losing', 'residents', 'to', 'its', 'neighbor', ',', 'it', '’', 's', 'rhode', 'island', '.', 'but', 'we', 'don', '’', 't', 'want', 'to', 'po', '##ach', 'rhode', 'islanders', '.', 'we', '’', 'd', 'rather', 'celebrate', 'electric', 'boat', '’', 's', 'growth', 'and', 'the', 'bu', '##rgeon', '##ing', 'workforce', 'that', 'supports', 'both', 'states', '.', 'we', '’', 'd', 'rather', 'cheer', 'cv', '##s', 'for', 'buying', 'ae', '##t', '##na', 'and', 'keeping', 'it', 'in', 'hartford', 'than', 'try', 'to', 'woo', 'cv', '##s', 'from', 'woo', '##ns', '##ock', '##et', '.', 'a', 'booming', 'connecticut', ',', 'especially', 'in', 'the', 'insurance', 'and', 'defense', 'industries', ',', 'only', 'helps', 'rhode', 'island', '.', 'as', 'electric', 'boat', '—', 'headquartered', 'in', 'connecticut', ',', 'might', 'we', 'emphasize', '—', 'grows', 'over', 'the', 'next', 'decade', ',', 'the', 'effect', 'on', 'little', 'r', '##ho', '##dy', 'will', 'be', 'profound', ',', 'as', 'the', 'pro', '##jo', '’', 's', 'editorial', 'board', 'pointed', 'out', '.', 'a', 'thriving', 'border', 'economy', 'helps', 'both', 'states', 'as', 'supplier', 'chains', 'develop', 'and', 'as', 'feeder', 'businesses', 'bloom', '.', 'but', 'for', 'the', 'same', 'reasons', 'that', 'the', 'stain', 'of', 'a', 'hartford', 'bankruptcy', 'would', 'spread', 'to', 'the', 'suburbs', ',', 'if', 'connecticut', 'becomes', 'an', 'economic', 'waste', '##land', ',', 'the', 'effects', 'would', 'be', 'felt', 'across', 'new', 'england', '.', 'if', 'rhode', 'island', 'and', 'connecticut', 'want', 'to', 'find', 'a', 'way', 'out', 'of', 'the', 'mu', '##ck', ',', 'far', 'better', 'for', 'them', 'to', 'work', 'together', '.', 'yes', ',', 'connecticut', 'can', 'learn', 'from', 'rhode', 'island', '.', 'connecticut', '’', 's', 'pension', 'problems', 'are', 'similar', 'to', 'those', 'that', 'threatened', 'to', 'swamp', 'rhode', 'island', ',', 'but', 'there', 'are', 'key', 'differences', ',', 'especially', 'in', 'that', 'connecticut', '’', 's', 'pensions', 'are', 'contractual', ',', 'where', 'in', 'rhode', 'island', ',', 'they', 'were', 'set', 'by', 'state', 'statute', '.', 'rhode', 'island', 'made', 'some', 'tough', 'choices', 'and', 'anticipated', 'a', 'legal', 'battle', 'to', 'solve', 'its', 'problems', '.', 'connecticut', 'leaders', 'might', 'have', 'to', 'find', 'the', 'stomach', 'for', 'the', 'same', 'type', 'of', 'strategy', '.', 'connecticut', 'and', 'rhode', 'island', 'have', 'a', 'lot', 'in', 'common', ',', 'including', 'language', '.', 'we', 'both', 'drive', 'around', 'the', 'rotary', 'to', 'get', 'a', 'grind', '##er', 'at', 'cum', '##bie', '’', 's', ',', 'for', 'example', '.', 'and', 'we', 'are', 'glad', 'that', 'rhode', 'island', 'has', 'made', 'progress', 'on', 'its', 'pension', 'issues', '.', 'but', 'that', '’', 's', 'no', 'reason', 'to', 'try', 'to', 'po', '##ach', 'a', 'few', 'residents', '.', 'a', 'regional', 'approach', 'would', 'be', 'much', 'wise', '##r', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMEmW7y9WFJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,x in enumerate(tokenized_texts):\n",
        "  if len(x)>512:\n",
        "    tokenized_texts[i]=tokenized_texts[i][:511]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmNPtgDVGo5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tokenized_texts = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBt-ex3USMh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_texts = pad_sequences(tokenized_texts, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KyzcUjUHaFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for seq in tokenized_texts:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhd9xHCTHn5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(tokenized_texts, labels, \n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, tokenized_texts,\n",
        "                                             random_state=2018, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN8PEsZdH2s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPERw50KIBNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "batch_size = 4\n",
        "\n",
        "\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0g5YldSS92B",
        "colab_type": "code",
        "outputId": "103fe452-3fe8-40f5-9337-c5d73f142a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_wPaaVjTAt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrI5Hgn1TDSq",
        "colab_type": "code",
        "outputId": "bda37422-88b3-4b0e-cc15-7e25507246b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ThMZpdqTIoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsuISmAGTW6q",
        "colab_type": "code",
        "outputId": "3083c1cd-3788-47fc-eb16-a1b87c7ee9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_tokenized_texts, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    logits = model(b_tokenized_texts, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy() \n",
        "    # Backward pass\n",
        "    loss_fct = CrossEntropyLoss()\n",
        "    loss = loss_fct(logits.view(-1, 2), label_ids.view(-1))\n",
        "    train_loss_set.append(loss.item()) \n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    if step%20==0:\n",
        "      break\n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_tokenized_texts.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_tokenized_texts, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_tokenized_texts, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    print(logits)\n",
        "    print(label_ids)\n",
        "    if batch%10==0:\n",
        "      break\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    #tmp_eval_f1 = f1_score(label_ids,logits)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    #eval_f1 += tmp_eval_f1\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "  #print(\"Validation f1: {}\".format(eval_f1/nb_eval_steps))\n",
        "  with open(\"models/bert.pickle\",\"wb\") as f:\n",
        "    pickle.dump(model,f)\n",
        "\n",
        "  \n",
        "\n",
        "with open(\"models/f_bert.pickle\",\"wb\") as f:\n",
        "  pickle.dump(model,f)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-2ad6662581be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mtrain_loss_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Type must be a sub-type of ndarray type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FZoRBA6nMpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2=open(\"models/bert.pickle\",\"rb\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr0Qbgld1_kb",
        "colab_type": "code",
        "outputId": "ec11db63-f874-4764-a20b-d71b66a653be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.eval()\n",
        "\n",
        "\n",
        "# Tracking variables \n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in validation_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_tokenized_texts, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_tokenized_texts, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  print(logits)\n",
        "  print(label_ids)\n",
        "  break\n",
        "  tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "  #tmp_eval_f1 = f1_score(label_ids,logits)\n",
        "  \n",
        "  eval_accuracy += tmp_eval_accuracy\n",
        "  #eval_f1 += tmp_eval_f1\n",
        "  nb_eval_steps += 1\n",
        "\n",
        "  #print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "  #print(\"Validation f1: {}\".format(eval_f1/nb_eval_steps))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.488819  -1.7009982]\n",
            " [ 1.488819  -1.7009981]\n",
            " [ 1.488819  -1.7009983]\n",
            " [ 1.4888188 -1.7009981]]\n",
            "[0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZf-kC-H2CDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), \"models/bert.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkMZqAgM3V5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = torch.load(\"models/bert.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGFifEmT3hDb",
        "colab_type": "code",
        "outputId": "6dee8b2c-18a9-4a92-c72a-bff16d935d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "model3.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-116c709d075e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYpKhXB44hov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train()\n",
        "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(tqdm_notebook(train_dataloader, desc=\"Iteration\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "\n",
        " \n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        loss = loss_fct(logits.view(-1, 2), label_ids.view(-1))\n",
        "        \n",
        "\n",
        "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
        "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "        loss.backward()\n",
        "        print(\"\\r%f\" % loss, end='')\n",
        "        \n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}